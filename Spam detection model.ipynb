{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "In this project we will build a spam filter! \n",
    "\n",
    "We'll use a classic dataset for this - UCI Repository SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import (Tokenizer, RegexTokenizer, StopWordsRemover, NGram, HashingTF,\n",
    "                                IDF, StringIndexer, CountVectorizer, VectorAssembler)\n",
    "from pyspark.sql.functions import col, udf, length\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we read in the data- which is in a tab delimited format. Spark's read.csv function allows you to specify the seperator, which in this case will be \\t. There is also no header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv('/user/a208669/SMSSpamCollection',inferSchema=True,header=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "|spam|FreeMsg Hey there...|\n",
      "| ham|Even my brother i...|\n",
      "| ham|As per your reque...|\n",
      "|spam|WINNER!! As a val...|\n",
      "|spam|Had your mobile 1...|\n",
      "| ham|I'm gonna be home...|\n",
      "|spam|SIX chances to wi...|\n",
      "|spam|URGENT! You have ...|\n",
      "| ham|I've been searchi...|\n",
      "| ham|I HAVE A DATE ON ...|\n",
      "|spam|XXXMobileMovieClu...|\n",
      "| ham|Oh k...i'm watchi...|\n",
      "| ham|Eh u remember how...|\n",
      "| ham|Fine if thats th...|\n",
      "|spam|England v Macedon...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's firstly rename the fields to more descriptive names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|  ham| 4827|\n",
      "| spam|  747|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('class').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage spam: 13.40%\n"
     ]
    }
   ],
   "source": [
    "print('Percentage spam: {0:.2f}%'.format(747/5574*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create a new field containing the length of the text message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.withColumn('length',length(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thats th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is a difference in the length of spam vs ham messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(lenght)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"class\").mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This field looks like it's predictive. Next we'll start a pipeline with the following stages:\n",
    "* Split the message into tokens - i.e. convert it to lower case and split the string by whitespace into a list of words\n",
    "* StopWordsRemover - Stop words are words which should be excluded from the input, typically because the words appear frequently and don’t carry as much meaning. StopWordsRemover takes as input a sequence of strings (e.g. the output of a Tokenizer) and drops all the stop words from the input sequences. The list of stopwords is specified by the stopWords parameter. Default stop words for some languages are accessible by calling StopWordsRemover.loadDefaultStopWords(language)\n",
    "* CountVectorizer - Count the number of times a particular word appear in the message\n",
    "* Compute the Inverse Document Frequency (IDF) given a collection of documents.\n",
    "* Convert class field to a numeric field so that it can be used in the Naive Bayes model\n",
    "* VectorAssembler : Assemble the feature columns into a feature vector.\n",
    "* Specifies that a naive bayes model will be fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol ='text',outputCol= 'token_text')\n",
    "stop_remove = StopWordsRemover(inputCol= 'token_text',outputCol = 'stop_token')\n",
    "count_vec = CountVectorizer(inputCol = 'stop_token', outputCol='c_vec')\n",
    "idf = IDF(inputCol = 'c_vec', outputCol='tf_idf')\n",
    "ham_spam_to_numeric = StringIndexer(inputCol = 'class', outputCol='label')\n",
    "assembler = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')\n",
    "nb_model = NaiveBayes(featuresCol='features',labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[ham_spam_to_numeric,\n",
    "                            tokenizer,\n",
    "                            stop_remove,\n",
    "                            count_vec,idf,\n",
    "                            assembler,\n",
    "                            nb_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the data into a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7,0.3],seed=78442)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can fit the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_detector = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see how well it performs on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = spam_detector.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- length: integer (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- token_text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- stop_token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- c_vec: vector (nullable = true)\n",
      " |-- tf_idf: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+\n",
      "|class|label|prediction|\n",
      "+-----+-----+----------+\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       0.0|\n",
      "|  ham|  0.0|       1.0|\n",
      "+-----+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.select('class','label','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll firstly calculate the acccuracy rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = acc_eval.evaluate(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 97.74%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy rate: {0:.2f}%'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the confusion matrix, we see that the model is not biased toward classifying all the SMSs as ham, which is indeed good news. The accuracy rate is however not the best metric to use, since it is dependent on the cut-off value you use for your probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+---+\n",
      "|label_prediction| 0.0|1.0|\n",
      "+----------------+----+---+\n",
      "|             1.0|  19|188|\n",
      "|             0.0|1453| 19|\n",
      "+----------------+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.crosstab('label','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next we'll calculate the Area under the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_eval2 = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "auc = acc_eval2.evaluate(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 94.77%\n"
     ]
    }
   ],
   "source": [
    "print('AUC: {0:.2f}%'.format(auc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all for a very rudimentary model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.4.5_Spark2.1.0",
   "language": "python",
   "name": "py345_spark210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
